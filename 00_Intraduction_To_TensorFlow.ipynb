{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9i2Dsh-ziXr"
   },
   "source": [
    "# Introduction to TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6sILUVbHoSgH",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "**TensorFlow** is an open-source machine learning library developed by Google, designed for building and training deep learning models. It uses **computational graphs** to represent data flow and supports efficient execution across **diverse hardware platforms**, including **CPUs, GPUs, and TPUs**. TensorFlow offers two execution modes: **eager execution** for intuitive, step-by-step debugging, and **graph execution** for optimized performance in production environments. At its core, TensorFlow relies on **tensors** (multi-dimensional arrays) that store and manipulate data throughout the model lifecycle, from input preprocessing to output prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1JcS5iBXMRO"
   },
   "source": [
    "## Configuration\n",
    "\n",
    "This section sets up the environment by installing and importing TensorFlow, preparing it for use throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running this notebook in Google Colab, TensorFlow is usually pre-installed.\n",
    "# To be sure, you can uncomment the line below and run it to install TensorFlow manually.\n",
    "\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T02:30:56.348575Z",
     "iopub.status.busy": "2024-08-16T02:30:56.348049Z",
     "iopub.status.idle": "2024-08-16T02:30:58.698400Z",
     "shell.execute_reply": "2024-08-16T02:30:58.697666Z"
    },
    "id": "vjBPmYjLdFmk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9UySOPLXdaw"
   },
   "source": [
    "## Tensors\n",
    "\n",
    "Tensors are the fundamental data structure in TensorFlow and they represent the flow of data through a computation graph. Tensors generalize scalars, vectors and matrices to higher dimensions. A tensor, in TensorFlow, is an object defined by:\n",
    "- **Shape:** Its dimensions (e.g., [2, 3] for a 2×3 matrix)\n",
    "- **Rank:** Number of dimensions (e.g., scalar = 0, vector = 1, matrix = 2)\n",
    "- **Data type:** Element type like float32, int32, or string\n",
    "- **Device:** Hardware location such as CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
      "Shape: (2, 3)\n",
      "Rank: 2\n",
      "Data type: <dtype: 'float32'>\n",
      "Device: /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "# Create a 2x3 tensor with float32 data type\n",
    "tensor = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=tf.float32)\n",
    "\n",
    "# Display tensor properties\n",
    "print(\"Tensor:\", tensor)                 # tf.Tensor([[1. 2. 3.] [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
    "print(\"Shape:\", tensor.shape)            # [2, 3]\n",
    "print(\"Rank:\", tf.rank(tensor).numpy())  # 2\n",
    "print(\"Data type:\", tensor.dtype)        # float32\n",
    "print(\"Device:\", tensor.device)          # e.g., '/job:localhost/replica:0/task:0/device:CPU:0'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic TensorFlow operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow provides a plethora of mathematical operations for manipulating tensors. The numerical operations include addition, subtraction, multiplication, division, and more:\n",
    "- `tf.constant()` is used for defining tensors.\n",
    "- `tf.add` is used to perform element-wise addition on tensors a and b.\n",
    "- `tf.subtract` is used for element-wise subtraction.\n",
    "- `tf.multiply` performs element-wise multiplication.\n",
    "- `tf.divide` is used for element-wise division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellView": "code",
    "execution": {
     "iopub.execute_input": "2024-08-16T02:30:58.702978Z",
     "iopub.status.busy": "2024-08-16T02:30:58.702447Z",
     "iopub.status.idle": "2024-08-16T02:31:00.907532Z",
     "shell.execute_reply": "2024-08-16T02:31:00.906788Z"
    },
    "id": "ngUe237Wt48W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a: tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
      "Tensor b: tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "Addition (a + b): tf.Tensor([3 6 9], shape=(3,), dtype=int32)\n",
      "Subtraction (a - b): tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "Multiplication (a * b): tf.Tensor([ 2  8 18], shape=(3,), dtype=int32)\n",
      "Division (a / b): tf.Tensor([2. 2. 2.], shape=(3,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define two tensors\n",
    "a = tf.constant([2, 4, 6])\n",
    "b = tf.constant([1, 2, 3])\n",
    "\n",
    "# Perform element-wise operations\n",
    "add_result = tf.add(a, b)\n",
    "sub_result = tf.subtract(a, b)\n",
    "mul_result = tf.multiply(a, b)\n",
    "div_result = tf.divide(a, b)\n",
    "\n",
    "# Display results\n",
    "print(\"Tensor a:\", a)\n",
    "print(\"Tensor b:\", b)\n",
    "print(\"Addition (a + b):\", add_result)\n",
    "print(\"Subtraction (a - b):\", sub_result)\n",
    "print(\"Multiplication (a * b):\", mul_result)\n",
    "print(\"Division (a / b):\", div_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[4, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to use normal operatrions (+, -, *, /) with tensors instead of tf functions !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDY4WsYRhP81"
   },
   "source": [
    "### Basic tensor transformations\n",
    "\n",
    "TensorFlow proposes many tensor transformations that modify tensors without changing their underlying data. These transformations include reshaping, transposing, casting, and slicing, and are key to preparing data for model training and evaluation in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped (2x3):\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "\n",
      "Expanded dims (axis=0):\n",
      " [[[1. 2.]\n",
      "  [3. 4.]\n",
      "  [5. 6.]]]\n",
      "\n",
      "Squeezed:\n",
      " [[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n",
      "\n",
      "Transposed:\n",
      " [[1. 3. 5.]\n",
      " [2. 4. 6.]]\n",
      "\n",
      "Reversed (axis=0):\n",
      " [[5. 6.]\n",
      " [3. 4.]\n",
      " [1. 2.]]\n",
      "\n",
      "Rolled (shift=1, axis=0):\n",
      " [[5. 6.]\n",
      " [1. 2.]\n",
      " [3. 4.]]\n",
      "\n",
      "Concatenated:\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "\n",
      "Stacked:\n",
      " [[[1 2]]\n",
      "\n",
      " [[3 4]]]\n",
      "\n",
      "Unstacked:\n",
      "Slice 0:\n",
      " [1. 2.]\n",
      "Slice 1:\n",
      " [3. 4.]\n",
      "Slice 2:\n",
      " [5. 6.]\n",
      "\n",
      "Split:\n",
      "Part 0:\n",
      " [[1. 2.]]\n",
      "Part 1:\n",
      " [[3. 4.]]\n",
      "Part 2:\n",
      " [[5. 6.]]\n",
      "\n",
      "Casted to int32:\n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      "Clipped (min=2, max=5):\n",
      " [[2. 2.]\n",
      " [3. 4.]\n",
      " [5. 5.]]\n",
      "\n",
      "Where condition:\n",
      " [[1. 0.]\n",
      " [0. 4.]\n",
      " [5. 6.]]\n",
      "\n",
      "Padded:\n",
      " [[0. 0. 0. 0.]\n",
      " [0. 1. 2. 0.]\n",
      " [0. 3. 4. 0.]\n",
      " [0. 5. 6. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "\n",
      "Sliced (first 2 rows, 2 cols):\n",
      " [[1. 2.]\n",
      " [3. 4.]]\n",
      "Sorted tensor (ascending): [[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n",
      "Original tensor:\n",
      " [[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n",
      "\n",
      "Shuffled tensor (rows randomly reordered):\n",
      " [[3. 4.]\n",
      " [5. 6.]\n",
      " [1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "# Base tensor\n",
    "x = tf.constant([[1, 2], [3, 4], [5, 6]], dtype=tf.float32)\n",
    "\n",
    "# 1. tf.reshape\n",
    "reshaped = tf.reshape(x, [2, 3])\n",
    "print(\"Reshaped (2x3):\\n\", reshaped.numpy())\n",
    "\n",
    "# 2. tf.expand_dims\n",
    "expanded = tf.expand_dims(x, axis=0)\n",
    "print(\"\\nExpanded dims (axis=0):\\n\", expanded.numpy())\n",
    "\n",
    "# 3. tf.squeeze\n",
    "squeezed = tf.squeeze(expanded)\n",
    "print(\"\\nSqueezed:\\n\", squeezed.numpy())\n",
    "\n",
    "# 4. tf.transpose\n",
    "transposed = tf.transpose(x)\n",
    "print(\"\\nTransposed:\\n\", transposed.numpy())\n",
    "\n",
    "# 5. tf.reverse\n",
    "reversed_tensor = tf.reverse(x, axis=[0])\n",
    "print(\"\\nReversed (axis=0):\\n\", reversed_tensor.numpy()\n",
    "\n",
    "# 6. tf.roll\n",
    "rolled = tf.roll(x, shift=1, axis=0)\n",
    "print(\"\\nRolled (shift=1, axis=0):\\n\", rolled.numpy())\n",
    "\n",
    "# 7. tf.concat\n",
    "a = tf.constant([[1, 2]])\n",
    "b = tf.constant([[3, 4]])\n",
    "concatenated = tf.concat([a, b], axis=0)\n",
    "print(\"\\nConcatenated:\\n\", concatenated.numpy())\n",
    "\n",
    "# 8. tf.stack\n",
    "stacked = tf.stack([a, b], axis=0)\n",
    "print(\"\\nStacked:\\n\", stacked.numpy())\n",
    "\n",
    "# 9. tf.unstack\n",
    "unstacked = tf.unstack(x, axis=0)\n",
    "print(\"\\nUnstacked:\")\n",
    "for i, t in enumerate(unstacked):\n",
    "    print(f\"Slice {i}:\\n\", t.numpy())\n",
    "\n",
    "# 10. tf.split\n",
    "split = tf.split(x, num_or_size_splits=3, axis=0)\n",
    "print(\"\\nSplit:\")\n",
    "for i, t in enumerate(split):\n",
    "    print(f\"Part {i}:\\n\", t.numpy())\n",
    "\n",
    "# 11. tf.cast\n",
    "casted = tf.cast(x, tf.int32)\n",
    "print(\"\\nCasted to int32:\\n\", casted.numpy())\n",
    "\n",
    "# 12. tf.clip_by_value\n",
    "clipped = tf.clip_by_value(x, clip_value_min=2.0, clip_value_max=5.0)\n",
    "print(\"\\nClipped (min=2, max=5):\\n\", clipped.numpy())\n",
    "\n",
    "# 13. tf.where\n",
    "condition = tf.constant([[True, False], [False, True], [True, True]])\n",
    "selected = tf.where(condition, x, tf.zeros_like(x))\n",
    "print(\"\\nWhere condition:\\n\", selected.numpy())\n",
    "\n",
    "# 14. tf.pad\n",
    "padded = tf.pad(x, paddings=[[1, 1], [1, 1]])\n",
    "print(\"\\nPadded:\\n\", padded.numpy())\n",
    "\n",
    "# 15. tf.slice\n",
    "sliced = tf.slice(x, begin=[0, 0], size=[2, 2])\n",
    "print(\"\\nSliced (first 2 rows, 2 cols):\\n\", sliced.numpy())\n",
    "\n",
    "# Reorder using tf.sort (ascending)\n",
    "sorted_tensor = tf.sort(x, direction='ASCENDING')\n",
    "print(\"Sorted tensor (ascending):\", sorted_tensor.numpy())\n",
    "\n",
    "# Shuffle along the first dimension (rows)\n",
    "shuffled = tf.random.shuffle(x)\n",
    "\n",
    "print(\"Original tensor:\\n\", x.numpy())\n",
    "print(\"\\nShuffled tensor (rows randomly reordered):\\n\", shuffled.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dwi1tdW3JBw6"
   },
   "source": [
    "### NumPy compatibility\n",
    "\n",
    "Converting between a TensorFlow `tf.Tensor` and a NumPy `ndarray` is easy:\n",
    "\n",
    "* TensorFlow operations automatically convert NumPy ndarrays to Tensors.\n",
    "* NumPy operations automatically convert Tensors to NumPy ndarrays.\n",
    "\n",
    "Tensors are explicitly converted to NumPy ndarrays using their `.numpy()` method. These conversions are typically cheap since the array and `tf.Tensor` share the underlying memory representation, if possible. However, sharing the underlying representation isn't always possible since the `tf.Tensor` may be hosted in GPU memory while NumPy arrays are always backed by host memory, and the conversion involves a copy from GPU to host memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T02:31:00.919071Z",
     "iopub.status.busy": "2024-08-16T02:31:00.918828Z",
     "iopub.status.idle": "2024-08-16T02:31:00.929627Z",
     "shell.execute_reply": "2024-08-16T02:31:00.929042Z"
    },
    "id": "lCUWzso6mbqR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow operations convert numpy arrays to Tensors automatically\n",
      "tf.Tensor(\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n",
      "And NumPy operations convert Tensors to NumPy arrays automatically\n",
      "[[43. 43. 43.]\n",
      " [43. 43. 43.]\n",
      " [43. 43. 43.]]\n",
      "The .numpy() method explicitly converts a Tensor to a numpy array\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\n",
    "tensor = tf.math.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "\n",
    "\n",
    "print(\"And NumPy operations convert Tensors to NumPy arrays automatically\")\n",
    "print(np.add(tensor, 1))\n",
    "\n",
    "print(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Modes in TensorFlow\n",
    "\n",
    "TensorFlow 2 simplifies development by blending two execution modes:\n",
    "\n",
    "- **Eager Execution:** Runs operations immediately, making it intuitive and Pythonic. Ideal for beginners, debugging, and rapid prototyping.\n",
    "- **Graph-Based Execution:** Builds a computational graph for optimized performance. Best suited for large-scale models and production deployment.\n",
    "\n",
    "With TensorFlow 2’s mixed approach, you can start in eager mode and later convert functions to graph mode using @tf.function. This lets you retain ease of use while gaining speed and scalability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution: 0.016597699839621782\n",
      "Graph execution: 0.18765489989891648\n",
      "For simple operations Graph execution takes more time..\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import tensorflow as tf\n",
    "# Eager function\n",
    "def func_eager(a,b):\n",
    "    return a*b\n",
    "# Graph function using tf.function on eager func\n",
    "@tf.function\n",
    "def graph_func(a,b): \n",
    "    return a*b \n",
    "\n",
    "a = tf.constant([2]) \n",
    "b = tf.constant([5])\n",
    "# Eager execution\n",
    "print(\"Eager execution:\",timeit.timeit(lambda:func_eager(a,b),number=100)) # Function with graph execution\n",
    "print(\"Graph execution:\",timeit.timeit(lambda: graph_func(a,b),number=100)) \n",
    "print(\"For simple operations Graph execution takes more time..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager time: 2.08488139975816\n",
      "Graph time: 0.9481501001864672\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow imports\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "# Define the model (Inspired by mnist inputs) \n",
    "model = tf.keras.Sequential() \n",
    "model.add(tf.keras.Input(shape=(28,28,))) \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(256,\"relu\")) \n",
    "model.add(Dense(128,\"relu\")) \n",
    "model.add(Dense(256,\"relu\"))\n",
    "model.add(Dense(10,\"softmax\")) \n",
    "\n",
    "\n",
    "# Dummy data with MNIST image sizes \n",
    "X = tf.random.uniform([1000, 28, 28])\n",
    "# Eager Execution to do inference (Model untrained as we are evaluating speed of inference)\n",
    "eager_model = model\n",
    "print(\"Eager time:\", timeit.timeit(lambda: eager_model(X,training=False), number=100))\n",
    "#Graph Execution to do inference (Model untrained as we are evaluating speed of inference)\n",
    "graph_model = tf.function(eager_model) \n",
    "# Wrap the model with tf.function \n",
    "print(\"Graph time:\", timeit.timeit(lambda: graph_model(X,training=False), number=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device Execution in TensorFlow: CPU, GPU, and TPU\n",
    "\n",
    "TensorFlow is designed to run computations efficiently across different hardware devices:\n",
    "\n",
    "- **CPU (Central Processing Unit):** Default execution device. Suitable for general-purpose tasks and small-scale models.\n",
    "- **GPU (Graphics Processing Unit):** Accelerates parallel computations, ideal for training deep learning models.\n",
    "- **TPU (Tensor Processing Unit):** Specialized hardware developed by Google for large-scale machine learning workloads.\n",
    "\n",
    "TensorFlow automatically assigns operations to available devices, but you can also manually place operations on a specific device using tf.device().\n",
    "\n",
    "⚠️ Note: GPU and TPU support depends on your environment. Google Colab typically provides GPU/TPU options via Runtime > Change runtime type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU execution time: 0.3260 seconds\n",
      "No GPU found. Skipping GPU test.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Create large tensors for demonstration\n",
    "x = tf.random.uniform([10000, 1000])\n",
    "y = tf.random.uniform([1000, 1000])\n",
    "\n",
    "# CPU execution\n",
    "with tf.device('/CPU:0'):\n",
    "    start_cpu = time.time()\n",
    "    result_cpu = tf.linalg.matmul(x, y)\n",
    "    end_cpu = time.time()\n",
    "    print(\"CPU execution time: {:.4f} seconds\".format(end_cpu - start_cpu))\n",
    "\n",
    "# GPU execution (if available)\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    with tf.device('/GPU:0'):\n",
    "        start_gpu = time.time()\n",
    "        result_gpu = tf.linalg.matmul(x, y)\n",
    "        end_gpu = time.time()\n",
    "        print(\"GPU execution time: {:.4f} seconds\".format(end_gpu - start_gpu))\n",
    "else:\n",
    "    print(\"No GPU found. Skipping GPU test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices:\n",
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices recognized by TensorFlow\n",
    "print(\"Available devices:\")\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1K4dlhhHtQj"
   },
   "source": [
    "## Datasets\n",
    "\n",
    "This section uses the `tf.data.Dataset` API to build a pipeline for feeding data to your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zI0fmOynH-Ne"
   },
   "source": [
    "### Create a source `Dataset`\n",
    "\n",
    "Create a *source* dataset using one of the factory functions like `tf.data.Dataset.from_tensors`, `tf.data.Dataset.from_tensor_slices`, or using objects that read from files like `tf.data.TextLineDataset` or `tf.data.TFRecordDataset`. Refer to the _Reading input data_ section of the [tf.data: Build TensorFlow input pipelines](../../guide/data.ipynb) guide for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T02:31:01.034880Z",
     "iopub.status.busy": "2024-08-16T02:31:01.034641Z",
     "iopub.status.idle": "2024-08-16T02:31:01.054294Z",
     "shell.execute_reply": "2024-08-16T02:31:01.053633Z"
    },
    "id": "F04fVOHQIBiG"
   },
   "outputs": [],
   "source": [
    "ds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbxIhC-5IPdf"
   },
   "source": [
    "### Apply transformations\n",
    "\n",
    "Use the transformations functions like `tf.data.Dataset.map`, `tf.data.Dataset.batch`, and `tf.data.Dataset.shuffle` to apply transformations to dataset records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T02:31:01.057854Z",
     "iopub.status.busy": "2024-08-16T02:31:01.057276Z",
     "iopub.status.idle": "2024-08-16T02:31:01.071743Z",
     "shell.execute_reply": "2024-08-16T02:31:01.071168Z"
    },
    "id": "uXSDZWE-ISsd"
   },
   "outputs": [],
   "source": [
    "ds_tensors = ds_tensors.map(tf.math.square).shuffle(2).batch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8X1GNfoIZKJ"
   },
   "source": [
    "### Iterate\n",
    "\n",
    "`tf.data.Dataset` objects support iteration to loop over records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T02:31:01.075147Z",
     "iopub.status.busy": "2024-08-16T02:31:01.074578Z",
     "iopub.status.idle": "2024-08-16T02:31:01.126484Z",
     "shell.execute_reply": "2024-08-16T02:31:01.125706Z"
    },
    "id": "ws-WKRk5Ic6-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements of ds_tensors:\n",
      "tf.Tensor([4 9], shape=(2,), dtype=int32)\n",
      "tf.Tensor([ 1 25], shape=(2,), dtype=int32)\n",
      "tf.Tensor([16 36], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print('Elements of ds_tensors:')\n",
    "for x in ds_tensors:\n",
    "  print(x)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "basics.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
