{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5923856",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNNs) with TensorFlow\n",
    "\n",
    "This notebook aims to provide a practical introduction to the fundamental concepts used in Convolutional Neural Networks (CNNs). The focus will be on the convolution operation, the application of filters to detect image features, and the function of pooling operations like max pooling. Finally, this notebook demonstrates how to implement a complete CNN using TensorFlow (TF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3fdca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ca0f80",
   "metadata": {},
   "source": [
    "Load a sample image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9624fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = tf.keras.utils.get_file(\"image.jpg\",\n",
    "#    \"https://ensit-edst.com/uploads/sliders/155aebede8668727eaef40e677f8102c.jpg\")\n",
    "\n",
    "image = tf.keras.utils.get_file(\"image.jpg\",\n",
    "    \"https://media.istockphoto.com/id/531314246/photo/adenocarcinoma.jpg?s=612x612&w=0&k=20&c=y0jJSS8HmIoT93b03FUwy_-Bj0Dr5NzhWyatDrhO2kE=\")\n",
    "\n",
    "img = tf.keras.utils.load_img(image, target_size=(408,612))\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "plt.imshow(img_array[0])\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc4a8cc",
   "metadata": {},
   "source": [
    "### Convolution\n",
    "Convolution applies a filter (kernel) across the image to detect features such as edges, textures, or patterns.\n",
    "- **Kernel**: a small matrix (e.g., 3×3) that slides over the image.\n",
    "- **Operation**: multiply element‑wise and sum to produce a new pixel value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e75bdb",
   "metadata": {},
   "source": [
    "#### Edge Detection\n",
    "This kernel highlights regions where pixel intensity changes sharply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b07bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple edge detection kernel\n",
    "edge_kernel = np.array([[-1, -1, -1],\n",
    "                        [-1,  8, -1],\n",
    "                        [-1, -1, -1]], dtype=np.float32)\n",
    "\n",
    "edge_kernel = edge_kernel.reshape((3,3,1,1))\n",
    "\n",
    "# Convert image to grayscale\n",
    "gray = tf.image.rgb_to_grayscale(img_array)\n",
    "\n",
    "# Apply convolution\n",
    "conv = tf.nn.conv2d(gray, edge_kernel, strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "# Visualize the result\n",
    "plt.imshow(conv[0,:,:,0], cmap=\"gray\")\n",
    "plt.title(\"Edge Detection via Convolution\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbb1cb8",
   "metadata": {},
   "source": [
    "#### Sharpening\n",
    "This kernel enhances fine details and makes edges more pronounced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d0f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpen_kernel = np.array([[0, -1, 0],\n",
    "                           [-1, 5, -1],\n",
    "                           [0, -1, 0]], dtype=np.float32)\n",
    "\n",
    "sharpen_kernel = sharpen_kernel.reshape((3,3,1,1))\n",
    "\n",
    "# Convert image to grayscale for simplicity\n",
    "gray = tf.image.rgb_to_grayscale(img_array)\n",
    "\n",
    "# Apply convolution\n",
    "conv = tf.nn.conv2d(gray, sharpen_kernel, strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "# Visualize the result\n",
    "plt.imshow(conv[0,:,:,0], cmap=\"gray\")\n",
    "plt.title(\"Sharpened Image via Convolution\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003c17d0",
   "metadata": {},
   "source": [
    "#### Blurring\n",
    "This kernel smooths the image, reducing noise and detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2a16ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_kernel = np.ones((5,5), dtype=np.float32) / 25.0\n",
    "\n",
    "blur_kernel = blur_kernel.reshape((5,5,1,1))\n",
    "\n",
    "# Convert image to grayscale for simplicity\n",
    "gray = tf.image.rgb_to_grayscale(img_array)\n",
    "\n",
    "# Apply convolution\n",
    "conv = tf.nn.conv2d(gray, blur_kernel, strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "# Visualize the result\n",
    "plt.imshow(conv[0,:,:,0], cmap=\"gray\")\n",
    "plt.title(\"Blurred Image via Convolution\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae19970",
   "metadata": {},
   "source": [
    "#### Embossing\n",
    "This kernel creates a 3D relief effect, making the image look raised or carved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bec722",
   "metadata": {},
   "outputs": [],
   "source": [
    "emboss_kernel = np.array([[-2, -1, 0],\n",
    "                          [-1,  1, 1],\n",
    "                          [0,   1, 2]], dtype=np.float32)\n",
    "\n",
    "emboss_kernel = emboss_kernel.reshape((3,3,1,1))\n",
    "\n",
    "# Convert image to grayscale for simplicity\n",
    "gray = tf.image.rgb_to_grayscale(img_array)\n",
    "\n",
    "# Apply convolution\n",
    "conv = tf.nn.conv2d(gray, emboss_kernel, strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "# Visualize the result\n",
    "plt.imshow(conv[0,:,:,0], cmap=\"gray\")\n",
    "plt.title(\"Embossed Image via Convolution\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb60f01",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "Pooling reduces the spatial dimensions of an image while preserving important features.\n",
    "- **Max Pooling**: keeps the maximum value in each region.\n",
    "- **Average Pooling**: computes the average value in each region.\n",
    "Pooling helps reduce computation and control overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624cafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max pooling\n",
    "max_pool = tf.nn.max_pool2d(gray, ksize=3, strides=2, padding=\"SAME\")\n",
    "\n",
    "# Average pooling\n",
    "avg_pool = tf.nn.avg_pool2d(gray, ksize=3, strides=2, padding=\"SAME\")\n",
    "\n",
    "# Visualize the result\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(gray[0,:,:,0], cmap=\"gray\")\n",
    "plt.title(\"Original Grayscale\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(max_pool[0,:,:,0], cmap=\"gray\")\n",
    "plt.title(\"Max Pooling\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(avg_pool[0,:,:,0], cmap=\"gray\")\n",
    "plt.title(\"Average Pooling\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7df420e",
   "metadata": {},
   "source": [
    "### Defining the CNN Architecture\n",
    "\n",
    "A typical CNN consists of alternating Convolutional (Conv2D) and Pooling (MaxPooling2D) layers, followed by a Flatten layer and Dense output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f477a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import numpy as np\n",
    "\n",
    "# Define the CNN model architecture\n",
    "cnn_model = Sequential([\n",
    "    # 1. Convolutional Layer: Learns 32 feature maps (filters)\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    \n",
    "    # 2. Pooling Layer: Reduces feature map size by half (28x28 -> 14x14)\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # 3. Another Conv Layer: Learns 64 features\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    \n",
    "    # 4. Another Pooling Layer: Reduces feature map size (14x14 -> 7x7)\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # 5. Flatten Layer: Flattens the 7x7x64 3D output into a 1D vector (3136 elements)\n",
    "    Flatten(),\n",
    "    \n",
    "    # 6. Dense Hidden Layer: Standard fully connected layer\n",
    "    Dense(128, activation='relu'),\n",
    "    \n",
    "    # 7. Output Layer: 10 units for 10 classes (Fashion MNIST)\n",
    "    Dense(10) # No activation here, as SparseCategoricalCrossentropy handles logits\n",
    "])\n",
    "\n",
    "# Display the model summary\n",
    "cnn_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
