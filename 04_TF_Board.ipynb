{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with TensorBoard in Jupyter/Colab\n",
    "\n",
    "**TensorBoard** is a powerful visualization tool provided with TensorFlow. It helps you understand, debug, and optimize your machine learning models by providing visualizations of the training process, model graphs, and other data.\n",
    "\n",
    "The following cell loads the necessary **Jupyter/Colab extension** to run TensorBoard directly within the notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "We import **TensorFlow (as `tf`)** for building and training the model, and the standard **`datetime`** library to create unique log directories for each training run. This is a best practice for tracking different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearing Previous Logs\n",
    "\n",
    "This command ensures that any old log files from previous, potentially incomplete, runs are removed. This prevents TensorBoard from trying to combine data from unrelated experiments, which can cause confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "! rm -rf logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing the MNIST Dataset\n",
    "\n",
    "We'll use the **MNIST dataset**, the \"Hello World\" of deep learning, for digit classification. \n",
    "\n",
    "* **Loading Data:** The data is loaded into training and testing sets.\n",
    "* **Normalization:** The pixel values (originally $0-255$) are scaled down to the range $0.0-1.0$ by dividing by $255.0$. This **normalization** is crucial for stable and faster model training.\n",
    "* **Model Definition:** A simple **Sequential Keras model** is defined, consisting of:\n",
    "    * **`Flatten`**: Converts the $28 \\times 28$ image into a flat $784$-element vector.\n",
    "    * **`Dense(512, activation='relu')`**: A hidden layer with 512 neurons and the **ReLU** activation function.\n",
    "    * **`Dropout(0.2)`**: Randomly sets 20% of the input units to 0 at each update during training, which is a powerful technique for preventing **overfitting**.\n",
    "    * **`Dense(10, activation='softmax')`**: The output layer with 10 neurons (for 10 classes) and the **softmax** activation, which provides probability scores for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring and Training the Model with the TensorBoard Callback\n",
    "\n",
    "This is the core section where we integrate TensorBoard into the Keras training process.\n",
    "\n",
    "* **Model Compilation:** The model is compiled with the **`adam`** optimizer and the **`sparse_categorical_crossentropy`** loss function (suitable for integer-labeled classification).\n",
    "* **Log Directory Creation:** A unique log directory path is created using the current timestamp. This allows running the training multiple times without overwriting previous results, making experiment comparison easy.\n",
    "* **`tf.keras.callbacks.TensorBoard`:** This **callback** is the bridge between the Keras training loop and TensorBoard. The key argument is:\n",
    "    * **`log_dir=log_dir`**: Specifies where to write the log files.\n",
    "    * **`histogram_freq=1`**: Tells TensorBoard to compute and log histogram data (weights and biases distributions) for the layers every epoch. This is highly valuable for debugging and seeing how weights change over time.\n",
    "* **`model.fit()`:** The training process begins. We pass the **`tensorboard_callback`** in the `callbacks` list, which enables the logging of metrics (loss, accuracy) and histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching TensorBoard\n",
    "\n",
    "This **magic command** starts the TensorBoard server and embeds the visualization interface directly into the output of this cell. It will display the logged metrics and histograms, allowing you to analyze the training performance. The `--logdir logs/fit` argument tells TensorBoard to look in the main log folder, where all our timestamped experiment folders reside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
